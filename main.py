from dotenv import load_dotenv
import asyncio
import json
import logging
import os
import random
from pathlib import Path

from aiogram import Bot, Dispatcher, F, types
from aiogram.filters import CommandStart
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from aiogram.fsm.storage.memory import MemoryStorage
from openai import AsyncOpenAI


load_dotenv()

BASE_DIR = Path(__file__).resolve().parent
RECIPES_PATH = BASE_DIR / "recipes.json"

with RECIPES_PATH.open("r", encoding="utf-8") as f:
    RECIPES = json.load(f)

if not isinstance(RECIPES, list) or not RECIPES:
    raise RuntimeError("recipes.json must contain a non-empty list of recipes")

TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

TRY_NEXT_BUTTON_TEXT = "ÐÐ¾Ð²Ð° ÑÑ‚Ñ€Ð°Ð²Ð°"

MAIN_KEYBOARD = types.ReplyKeyboardMarkup(
    keyboard=[[types.KeyboardButton(text=TRY_NEXT_BUTTON_TEXT)]],
    resize_keyboard=True,
    one_time_keyboard=False,
)


class QuizStates(StatesGroup):
    waiting_for_answer = State()


openai_client: AsyncOpenAI | None = None


async def start_handler(message: types.Message) -> None:
    """
    Handle /start command and show the main button.
    """
    await message.answer(
        "Ð‘Ð¾Ñ‚, ÑÐºÐ¸Ð¹ Ð´Ð¾Ð¿Ð¾Ð¼Ð¾Ð¶Ðµ Ñ‚Ð¾Ð±Ñ– Ð²Ð¸Ð²Ñ‡Ð¸Ñ‚Ð¸ Ð²ÑÑ– Ñ€ÐµÑ†ÐµÐ¿Ñ‚Ð¸.",
        reply_markup=MAIN_KEYBOARD,
    )


async def handle_try_next(message: types.Message, state: FSMContext) -> None:
    """
    Handle pressing the 'Try next' button:
    - pick a random dish
    - ask user to write its recipe
    """
    dish = random.choice(RECIPES)

    # Store current dish in state for future extensions (e.g. checking answer)
    await state.update_data(current_dish_name=dish.get("name"))
    await state.set_state(QuizStates.waiting_for_answer)

    await message.answer(
        f"Ð¡Ñ‚Ñ€Ð°Ð²Ð°: {dish.get('name')}\n\nÐ‘ÑƒÐ´ÑŒ Ð»Ð°ÑÐºÐ°, Ð½Ð°Ð¿Ð¸ÑˆÑ–Ñ‚ÑŒ Ð¹Ð¾Ð³Ð¾ Ñ€ÐµÑ†ÐµÐ¿Ñ‚.",
        reply_markup=MAIN_KEYBOARD,
    )


async def evaluate_answer_with_model(
    dish_name: str, official_recipe: str, user_recipe: str
) -> str:
    """
    Use OpenAI model to compare user's recipe with the official one and rate it.
    """
    if openai_client is None:
        return (
            "Evaluation service is temporarily unavailable. "
            "Please try another dish later."
        )

    prompt = """
    Ð¢Ð¸ â€“ ÐµÐºÑÐ¿ÐµÑ€Ñ‚-ÑˆÐµÑ„-ÐºÑƒÑ…Ð°Ñ€, ÑÐºÐ¸Ð¹ Ð¿Ñ€Ð¾Ð²Ð¾Ð´Ð¸Ñ‚ÑŒ Ñ‚ÐµÑÑ‚Ð¸ Ð´Ð»Ñ Ð²Ñ–Ð´Ð±Ð¾Ñ€Ñƒ ÐºÑƒÑ…Ð°Ñ€Ñ–Ð² Ñƒ Ñ€ÐµÑÑ‚Ð¾Ñ€Ð°Ð½.

    Ð£ ÑÐ²Ð¾Ñ—Ð¹ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ– Ð¼Ð¾Ð¶ÐµÑˆ Ð·Ð²ÐµÑ€Ñ‚Ð°Ñ‚Ð¸ÑÑ Ð±ÐµÐ·Ð¿Ð¾ÑÐµÑ€ÐµÐ´Ð½ÑŒÐ¾ Ð´Ð¾ ÐºÐ°Ð½Ð´Ð¸Ð´Ð°Ñ‚Ð°. ÐÐ°Ð¿Ñ€Ð¸ÐºÐ»Ð°Ð´: "Ð¢Ð¸ Ð½Ð°Ð¿Ð¸ÑÐ°Ð²...", "Ð¢Ð¾Ð±Ñ– Ñ‚Ñ€ÐµÐ±Ð°...".

    ÐŸÑ€Ð°Ð²Ð¸Ð»Ð°:
    1) Ð¡Ð¿Ñ–Ð»ÐºÑƒÐ¹ÑÑ Ñ‚Ñ–Ð»ÑŒÐºÐ¸ ÑƒÐºÑ€Ð°Ñ—Ð½ÑÑŒÐºÐ¾ÑŽ, Ð½Ð°Ð²Ñ–Ñ‚ÑŒ ÑÐºÑ‰Ð¾ Ñ€ÐµÑ†ÐµÐ¿Ñ‚ ÐºÐ°Ð½Ð´Ð¸Ð´Ð°Ñ‚Ð° Ð½Ð°Ð¿Ð¸ÑÐ°Ð½Ð¸Ð¹ Ñ€Ð¾ÑÑ–Ð¹ÑÑŒÐºÐ¾ÑŽ.
    2) ÐŸÐ¾Ñ€Ñ–Ð²Ð½ÑÐ¹ Ñ€ÐµÑ†ÐµÐ¿Ñ‚ ÐºÐ°Ð½Ð´Ð¸Ð´Ð°Ñ‚Ð° Ð· Ð¾Ñ„Ñ–Ñ†Ñ–Ð¹Ð½Ð¸Ð¼ Ñ– ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¾ Ð¾Ñ†Ñ–Ð½ÑŽÐ¹, Ð½Ð°ÑÐºÑ–Ð»ÑŒÐºÐ¸ Ð²Ð¾Ð½Ð¸ Ð·Ð±Ñ–Ð³Ð°ÑŽÑ‚ÑŒÑÑ.
    3) Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ– â€” ÑÑ‚Ð¸ÑÐ»Ð¾, Ñƒ ÑÑ‚Ð¸Ð»Ñ– Telegram: 4â€“5 ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ñ… Ñ€ÐµÑ‡ÐµÐ½ÑŒ.
    4) Ð’Ð¸Ð´Ñ–Ð»ÑÐ¹ Ð³Ð¾Ð»Ð¾Ð²Ð½Ñ– Ñ€Ð¾Ð·Ð±Ñ–Ð¶Ð½Ð¾ÑÑ‚Ñ–, Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ¸ Ð°Ð±Ð¾ Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ¸.
    5) Ð—Ð°Ð²Ð¶Ð´Ð¸ Ð´Ð¾Ð´Ð°Ð²Ð°Ð¹ Ð¾ÐºÑ€ÐµÐ¼Ð¸Ð¼ Ñ€ÑÐ´ÐºÐ¾Ð¼: ðŸ“ ÐžÑ†Ñ–Ð½ÐºÐ°: X/10 (Ñ†Ñ–Ð»Ðµ Ñ‡Ð¸ÑÐ»Ð¾, Ð´Ðµ 10 = Ð¼Ð°Ð¹Ð¶Ðµ Ñ–Ð´ÐµÐ½Ñ‚Ð¸Ñ‡Ð½Ð¸Ð¹).
    6) (ÐžÐŸÐ¦Ð†ÐžÐÐÐ›Ð¬ÐÐž) Ð¯ÐºÑ‰Ð¾ Ð¼Ð¾Ð¶Ð»Ð¸Ð²Ð¾, Ð´Ð°Ð¹ Ð¾Ð´Ð½Ñƒ Ð´ÑƒÐ¶Ðµ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÑƒ, Ð¿Ñ€Ð°ÐºÑ‚Ð¸Ñ‡Ð½Ñƒ Ð¿Ð¾Ñ€Ð°Ð´Ñƒ, ÑÐº ÐºÑ€Ð°Ñ‰Ðµ Ð·Ð°Ð¿Ð°Ð¼â€™ÑÑ‚Ð°Ñ‚Ð¸ ÑÐ°Ð¼Ðµ Ñ†ÐµÐ¹ Ñ€ÐµÑ†ÐµÐ¿Ñ‚ (Ð±ÐµÐ· Ð°Ð±ÑÑ‚Ñ€Ð°ÐºÑ†Ñ–Ð¹). Ð’Ñ–Ð´Ð¾ÐºÑ€ÐµÐ¼ Ñ—Ñ— Ð²Ñ–Ð´ Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð³Ð¾ Ñ‚ÐµÐºÑÑ‚Ñƒ Ð½ÑŒÑŽÐ»Ð°Ð¹Ð½Ð°Ð¼Ð¸ Ñ‚Ð° ÐºÑ–Ð»ÑŒÐºÐ¾Ð¼Ð° Ñ‚Ð¸Ñ€Ðµ (---)

    Ð’Ñ…Ñ–Ð´Ð½Ñ– Ð´Ð°Ð½Ñ–:
    - ÐÐ°Ð·Ð²Ð° ÑÑ‚Ñ€Ð°Ð²Ð¸: {dish_name}
    - ÐžÑ„Ñ–Ñ†Ñ–Ð¹Ð½Ð¸Ð¹ Ñ€ÐµÑ†ÐµÐ¿Ñ‚: {official_recipe}
    - Ð ÐµÑ†ÐµÐ¿Ñ‚ ÐºÐ°Ð½Ð´Ð¸Ð´Ð°Ñ‚Ð°: {user_recipe}

    Ð—Ð°Ð²Ð´Ð°Ð½Ð½Ñ:
    ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ñ–Ð·ÑƒÐ¹ Ñ‚Ð° ÑÑ„Ð¾Ñ€Ð¼ÑƒÐ¹ Ð¿Ñ–Ð´ÑÑƒÐ¼Ð¾Ðº Ð·Ð³Ñ–Ð´Ð½Ð¾ Ð· Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð°Ð¼Ð¸.
    """
    prompt = prompt.format(dish_name=dish_name, official_recipe=official_recipe, user_recipe=user_recipe)
    response = await openai_client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {
                "role": "system",
                "content": "Ð’Ð¸ Ð»Ð°ÐºÐ¾Ð½Ñ–Ñ‡Ð½Ð¸Ð¹, ÑÑƒÐ²Ð¾Ñ€Ð¸Ð¹ Ð¾Ñ†Ñ–Ð½ÑŽÐ²Ð°Ñ‡ Ñ€ÐµÑ†ÐµÐ¿Ñ‚Ñ–Ð².",
            },
            {"role": "user", "content": prompt},
        ],
        max_tokens=200,
        temperature=0.3,
    )

    return (response.choices[0].message.content or "").strip()


async def handle_answer(message: types.Message, state: FSMContext) -> None:
    """
    Handle user's recipe answer.
    """
    data = await state.get_data()
    dish_name = data.get("current_dish_name")

    dish = None
    if dish_name:
        dish = next((d for d in RECIPES if d.get("name") == dish_name), None)

    if not dish:
        # Fallback if we, for some reason, lost the dish in state
        await message.answer(
            "I couldn't find the official recipe this time, "
            "but you can try another dish.",
            reply_markup=MAIN_KEYBOARD,
        )
        await state.clear()
        return

    official_recipe = dish.get("recipe") or "No recipe description available."
    user_recipe = message.text or ""

    evaluation = await evaluate_answer_with_model(
        dish.get("name", "Unknown dish"),
        official_recipe,
        user_recipe,
    )

    image_url = dish.get("image_url")

    # Send only model response and image (if available)
    if image_url:
        await message.answer_photo(
            photo=image_url,
            caption=evaluation,
            reply_markup=MAIN_KEYBOARD,
        )
    else:
        await message.answer(evaluation, reply_markup=MAIN_KEYBOARD)

    # Clear state so user can start a new round by pressing the button again
    await state.clear()


async def main() -> None:
    """
    Entry point for the Telegram bot.
    """
    # Basic logging setup
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    )

    if not TELEGRAM_BOT_TOKEN:
        raise RuntimeError("TELEGRAM_BOT_TOKEN is not set in the environment")
    if not OPENAI_API_KEY:
        raise RuntimeError("OPENAI_API_KEY is not set in the environment")

    global openai_client
    openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)

    bot = Bot(token=TELEGRAM_BOT_TOKEN)
    dp = Dispatcher(storage=MemoryStorage())

    # Register handlers
    dp.message.register(start_handler, CommandStart())
    dp.message.register(handle_try_next, F.text == TRY_NEXT_BUTTON_TEXT)
    dp.message.register(handle_answer, QuizStates.waiting_for_answer)

    # Start polling
    await dp.start_polling(bot)


if __name__ == "__main__":
    asyncio.run(main())
